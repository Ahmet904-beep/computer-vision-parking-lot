{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parking Spot Detection Notebook\n",
        "\n",
        "This notebook demonstrates a workflow for detecting and classifying parking spots as either \"Occupied\" or \"Empty\" in a video feed. The process involves:\n",
        "\n",
        "1. **Loading Required Libraries**: Importing necessary libraries for image processing, machine learning, and video manipulation.\n",
        "2. **Defining Constants**: Setting paths for the model, video, and mask files, as well as image size for preprocessing.\n",
        "3. **Helper Functions**: Implementing functions for extracting parking spot bounding boxes, preparing images for the model, and predicting the status of parking spots.\n",
        "4. **Model Loading**: Loading a pre-trained TensorFlow model for classification.\n",
        "5. **Video Processing**: Reading the video feed, applying the mask, and detecting parking spot statuses in real-time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfkKXMFqFdUK"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "# from google.colab.patches import cv2_imshow # for displaying images in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrhoPmcFtkh"
      },
      "outputs": [],
      "source": [
        "# Models directory\n",
        "MODELS_DIRECTORY = '../model/model.keras'\n",
        "\n",
        "# Video path\n",
        "VIDEO_PATH = '../video/parking_1920_1080_loop.mp4'\n",
        "\n",
        "# Mask path\n",
        "MASK_PATH = '../video//mask_1920_1080.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BhIL9lo8id_9"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rig3WJTfLOQz"
      },
      "outputs": [],
      "source": [
        "# Get the parking spots bounding boxes\n",
        "def get_parking_spots_bboxes(connected_components):\n",
        "    \"\"\"\n",
        "    Get the parking spots bounding boxes from the connected components.\n",
        "\n",
        "    Parameters:\n",
        "        -connected_components : tuple\n",
        "    Returns\n",
        "        - parking_spots_bboxes : list of tuples\n",
        "    \"\"\"\n",
        "    # connected_components\n",
        "    (totalLabels, label_ids, values, centroid) = connected_components\n",
        "\n",
        "    # Get the parking spots bounding boxes\n",
        "    parking_spots_bboxes = []\n",
        "\n",
        "    # Get the parking spots bounding boxes\n",
        "    # The first label is the background, so we start from 1\n",
        "    coef = 1\n",
        "    for i in range(1, totalLabels):\n",
        "        x = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
        "        y = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
        "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
        "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
        "        parking_spots_bboxes.append((x, y, w, h))\n",
        "        \n",
        "    return parking_spots_bboxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mouFaidLcg8x"
      },
      "outputs": [],
      "source": [
        "# Preape the image for the model\n",
        "def load_and_prepare_image(image):\n",
        "    \"\"\"\n",
        "    Load and prepare the image for the model.\n",
        "\n",
        "    Parameters:\n",
        "        - image : numpy array\n",
        "\n",
        "    Returns:\n",
        "        - img : TensorFlow tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert to Tensor and ensure it's float32\n",
        "    img = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "\n",
        "    # Ensure image has 3 channels\n",
        "    if img.shape[-1] != 3:\n",
        "        raise ValueError(f\"Expected image with 3 channels, got shape: {img.shape}\")\n",
        "\n",
        "    # Resize to match model input\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "\n",
        "    # Add batch dimension\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EleXjxPybhTO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Arturo\\Documents\\Annie_DAML_course\\comp_vi_project\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = tf.keras.models.load_model(MODELS_DIRECTORY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTKNmiFIQD7F"
      },
      "outputs": [],
      "source": [
        "# Predict empty of not empty\n",
        "def empty_or_not(spot_crop):\n",
        "    \"\"\"\n",
        "    Predict if the parking spot is empty or not.\n",
        "\n",
        "    Parameters:\n",
        "        - spot_crop : numpy array\n",
        "\n",
        "    Returns:\n",
        "        - status : str\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load and prepare image\n",
        "    image = load_and_prepare_image(spot_crop)\n",
        "\n",
        "    # Predict\n",
        "    y_out = model.predict(image)\n",
        "\n",
        "    if y_out > 0.5:\n",
        "        status = 'Occupied'\n",
        "    else:\n",
        "        status = 'Empty'\n",
        "\n",
        "    return status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3QKMBL2oKpVj"
      },
      "outputs": [],
      "source": [
        "# Load video and mask and connect\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "mask = cv2.imread(MASK_PATH, cv2.IMREAD_GRAYSCALE)\n",
        "connected_components = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "\n",
        "# Get the parking spots\n",
        "parking_spots_bboxes = get_parking_spots_bboxes(connected_components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mUDy40NMLFeu",
        "outputId": "2e5e8a20-064c-4512-c3cf-d2af2fa80029"
      },
      "outputs": [],
      "source": [
        "ret = True\n",
        "step = 30\n",
        "spots_status = [None for _ in parking_spots_bboxes]\n",
        "frame_nmr = 0\n",
        "\n",
        "# Loop through the video frames\n",
        "while ret:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "      \n",
        "      for spot_id, parking_spot_bbox in enumerate(parking_spots_bboxes):\n",
        "\n",
        "          x, y, w, h = parking_spot_bbox\n",
        "          spot_crop = frame[y:y+h, x:x+w, :]\n",
        "\n",
        "          spot_status = empty_or_not(spot_crop)\n",
        "          spots_status[spot_id] = spot_status\n",
        "\n",
        "    occupied_count = spots_status.count('Occupied')  # Count 'Occupied' in the list\n",
        "\n",
        "    # Draw the parking spots on the frame\n",
        "    for spot_id, parking_spot_bbox in enumerate(parking_spots_bboxes):\n",
        "\n",
        "      spot_status = spots_status[spot_id]\n",
        "      x, y, w, h = parking_spot_bbox\n",
        "\n",
        "      if spot_status == 'Occupied':\n",
        "          color = (0, 0, 255)\n",
        "      else:\n",
        "          color = (0, 255, 0)\n",
        "      frame = cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "    cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
        "    cv2.putText(frame, f\"Available spots: {len(spots_status) - occupied_count} / {len(spots_status)}\", (100, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "    cv2.imshow(\"Frame\", frame) # Comment if not running in Google Colab\n",
        "    #cv2_imshow(frame) # Uncomment if running in Google Colab\n",
        "    frame_nmr += 1\n",
        "\n",
        "    if frame_nmr > 120:\n",
        "        print(\"Stopping after 120 frames\")\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "comp_vi_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
